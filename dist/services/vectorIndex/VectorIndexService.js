"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.vectorIndexService = exports.VectorIndexService = void 0;
const crypto_1 = require("crypto");
const path = __importStar(require("path"));
const s3Service_1 = require("../s3Service");
const lambdaIndexer_1 = require("../lambdaIndexer");
const EmbeddingService_1 = require("./EmbeddingService");
const FaissIndexManager_1 = require("./FaissIndexManager");
const CheckpointManager_1 = require("./CheckpointManager");
const JobLockManager_1 = require("./JobLockManager");
const vectorIndex_1 = require("../../types/vectorIndex");
const client_s3_1 = require("@aws-sdk/client-s3");
const fs = __importStar(require("fs"));
const crypto = __importStar(require("crypto"));
const s3Client = new client_s3_1.S3Client({ region: process.env.AWS_REGION || 'us-east-1' });
const s3BucketName = process.env.S3_BUCKET_NAME || '';
const DEFAULT_CONFIG = {
    batchSize: 100,
    maxChunksInMemory: 100,
    maxVectorsInMemory: 500,
    checkpointInterval: 50,
    gcInterval: 200,
    maxRetries: 3,
    embeddingModel: 'text-embedding-3-small',
    dimensions: 1536,
    indexType: 'hnsw',
};
class VectorIndexService {
    constructor(config = {}) {
        this.jobs = new Map();
        this.tempDir = './data/temp';
        this.jobsLoaded = false;
        this.JOB_RETENTION_DAYS = 7;
        this.config = { ...DEFAULT_CONFIG, ...config };
        this.embeddingService = new EmbeddingService_1.EmbeddingService(this.config.embeddingModel, this.config.dimensions, this.config.maxRetries);
        this.jobLockManager = new JobLockManager_1.JobLockManager();
        this.checkpointManager = new CheckpointManager_1.CheckpointManager();
        if (!fs.existsSync(this.tempDir)) {
            fs.mkdirSync(this.tempDir, { recursive: true });
        }
        // å•Ÿå‹•æ™‚å¾ S3 è¼‰å…¥ jobs
        this.loadJobsFromS3().catch(error => {
            console.error('Failed to load jobs from S3:', error);
        });
        // æ¯å¤©æ¸…ç†ä¸€æ¬¡éæœŸçš„ jobs
        setInterval(() => {
            this.cleanupOldJobsFromS3().catch(error => {
                console.error('Failed to cleanup old jobs:', error);
            });
        }, 24 * 60 * 60 * 1000); // 24 å°æ™‚
    }
    /**
     * å•Ÿå‹•å‘é‡ç´¢å¼•ä»»å‹™
     */
    async startIndexing(fileId, fileName, forceRebuild = false) {
        // å…ˆæ¸…ç†éæœŸçš„é–å®š
        this.jobLockManager.cleanupExpiredLocks();
        // æª¢æŸ¥å…¨åŸŸé–å®š
        if (this.jobLockManager.isGloballyLocked()) {
            if (!forceRebuild) {
                throw new Error('Another indexing job is in progress. Please wait.');
            }
            console.warn('Force rebuild requested, releasing existing lock');
            this.jobLockManager.releaseGlobalLock();
        }
        // æª¢æŸ¥æª”æ¡ˆé–å®š
        if (this.jobLockManager.isFileLocked(fileId)) {
            if (!forceRebuild) {
                throw new Error(`File ${fileId} is already being indexed.`);
            }
            console.warn(`Force rebuild requested for file ${fileId}, releasing existing lock`);
            this.jobLockManager.releaseFileLock(fileId);
        }
        const jobId = crypto_1.randomUUID();
        // å–å¾—å…¨åŸŸé–å®š
        if (!this.jobLockManager.acquireGlobalLock(jobId)) {
            throw new Error('Failed to acquire global lock');
        }
        // å–å¾—æª”æ¡ˆé–å®š
        if (!this.jobLockManager.acquireFileLock(fileId, jobId)) {
            this.jobLockManager.releaseGlobalLock();
            throw new Error(`Failed to acquire lock for file ${fileId}`);
        }
        // å»ºç«‹ä»»å‹™
        const job = {
            jobId,
            fileId,
            fileName,
            status: vectorIndex_1.VectorIndexStatus.PENDING,
            stage: vectorIndex_1.VectorIndexStage.INITIALIZATION,
            progress: {
                current: 0,
                total: 0,
                percentage: 0,
            },
            createdAt: new Date(),
            updatedAt: new Date(),
        };
        this.jobs.set(jobId, job);
        // ä¿å­˜ job åˆ° S3
        await this.saveJobToS3(job);
        // åœ¨èƒŒæ™¯åŸ·è¡Œç´¢å¼•
        this.processIndexing(jobId, fileId, fileName).catch(error => {
            console.error(`Indexing job ${jobId} failed:`, error);
            this.handleJobError(jobId, error);
            // ç¢ºä¿é‡‹æ”¾é–å®š
            this.cleanup(jobId, fileId);
        });
        return jobId;
    }
    /**
     * è™•ç†ç´¢å¼•æµç¨‹ (ä½¿ç”¨ Lambda è™•ç†)
     */
    async processIndexing(jobId, fileId, fileName) {
        const job = this.jobs.get(jobId);
        if (!job) {
            console.error(`Job ${jobId} not found`);
            return;
        }
        try {
            // æ›´æ–°ä»»å‹™ç‹€æ…‹ç‚ºé€²è¡Œä¸­
            job.status = vectorIndex_1.VectorIndexStatus.EXTRACTING;
            job.stage = vectorIndex_1.VectorIndexStage.TEXT_EXTRACTION;
            job.updatedAt = new Date();
            // ç²å–æª”æ¡ˆçš„ S3 Key
            const files = await s3Service_1.s3Service.listFiles();
            const fileMetadata = files.find(f => f.id === fileId);
            if (!fileMetadata) {
                throw new Error(`File metadata not found for ${fileId}`);
            }
            console.log(`ğŸš€ Triggering Lambda indexer for ${fileName} (${fileId})`);
            console.log(`   S3 Key: ${fileMetadata.s3Key}`);
            // è§¸ç™¼ Lambda ç´¢å¼•
            const success = await lambdaIndexer_1.lambdaIndexerService.triggerIndexing(fileId, fileName, fileMetadata.s3Key, jobId);
            if (success) {
                // Lambda å·²æˆåŠŸè§¸ç™¼ï¼Œæ›´æ–°ä»»å‹™ç‹€æ…‹
                job.status = vectorIndex_1.VectorIndexStatus.INDEXING;
                job.stage = vectorIndex_1.VectorIndexStage.INDEX_BUILDING;
                job.updatedAt = new Date();
                console.log(`âœ… Lambda indexer triggered successfully for ${fileName}`);
                console.log(`   Job ID: ${jobId}`);
                console.log(`   Lambda will callback when indexing completes`);
            }
            else {
                throw new Error('Failed to trigger Lambda indexer');
            }
        }
        catch (error) {
            console.error(`âŒ Lambda indexing failed for ${fileName}:`, error.message);
            if (job) {
                job.status = vectorIndex_1.VectorIndexStatus.FAILED;
                job.error = error.message;
                job.updatedAt = new Date();
            }
        }
        finally {
            // æ³¨æ„ï¼šä¸è¦åœ¨é€™è£¡é‡‹æ”¾é–å®š
            // Lambda callback æœƒè² è²¬å®Œæˆå¾Œçš„æ¸…ç†å·¥ä½œ
        }
    }
    /**
     * å¾é€²åº¦è¿½è¹¤å™¨æ›´æ–°ä»»å‹™
     */
    updateJobFromTracker(jobId, tracker) {
        const job = this.jobs.get(jobId);
        if (job) {
            const stats = tracker.getStats();
            job.status = stats.currentStatus;
            job.stage = stats.currentStage;
            job.progress = stats.progress;
            job.updatedAt = new Date();
        }
    }
    /**
     * è™•ç†ä»»å‹™éŒ¯èª¤
     */
    handleJobError(jobId, error) {
        const job = this.jobs.get(jobId);
        if (job) {
            job.status = vectorIndex_1.VectorIndexStatus.FAILED;
            job.error = error.message || String(error);
            job.updatedAt = new Date();
            // é‡‹æ”¾é–å®š
            if (job.fileId) {
                this.jobLockManager.releaseFileLock(job.fileId);
            }
            this.jobLockManager.releaseGlobalLock();
        }
    }
    /**
     * ä¸Šå‚³æª”æ¡ˆåˆ° S3
     */
    async uploadFileToS3(localPath, s3Key) {
        const fileContent = fs.readFileSync(localPath);
        await s3Client.send(new client_s3_1.PutObjectCommand({
            Bucket: s3BucketName,
            Key: s3Key,
            Body: fileContent,
        }));
        return `s3://${s3BucketName}/${s3Key}`;
    }
    /**
     * è¨ˆç®—æª”æ¡ˆ checksum
     */
    async calculateChecksum(filePath) {
        const content = fs.readFileSync(filePath);
        return crypto.createHash('sha256').update(content).digest('hex');
    }
    /**
     * æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
     */
    cleanup(jobId, fileId, ...filePaths) {
        // åˆªé™¤è‡¨æ™‚æª”æ¡ˆ
        for (const filePath of filePaths) {
            if (fs.existsSync(filePath)) {
                fs.unlinkSync(filePath);
            }
        }
        // é‡‹æ”¾é–å®š
        this.jobLockManager.releaseFileLock(fileId);
        this.jobLockManager.releaseGlobalLock();
        console.log(`Cleanup completed for job ${jobId}`);
    }
    /**
     * å–å¾—ä»»å‹™ç‹€æ…‹
     */
    getJob(jobId) {
        const job = this.jobs.get(jobId);
        if (!job)
            return undefined;
        const now = Date.now();
        const timeout = 15 * 60 * 1000; // 15 åˆ†é˜è¶…æ™‚
        // æª¢æŸ¥æ˜¯å¦è¶…æ™‚ï¼ˆåªæª¢æŸ¥æœªå®Œæˆçš„ä»»å‹™ï¼‰
        if (!job.completedAt && // æ²’æœ‰å®Œæˆæ™‚é–“
            (job.status === vectorIndex_1.VectorIndexStatus.INDEXING ||
                job.status === vectorIndex_1.VectorIndexStatus.EXTRACTING ||
                job.status === vectorIndex_1.VectorIndexStatus.PENDING) &&
            now - job.createdAt.getTime() > timeout) {
            console.warn(`Job ${job.jobId} has timed out after ${timeout / 1000}s`);
            job.status = vectorIndex_1.VectorIndexStatus.FAILED;
            job.error = `Timeout: No callback received after ${timeout / 60000} minutes. Lambda may have failed silently.`;
            job.updatedAt = new Date();
            // é‡‹æ”¾é–å®š
            this.jobLockManager.releaseFileLock(job.fileId);
            this.jobLockManager.releaseGlobalLock();
            // ä¿å­˜æ›´æ–°åˆ° S3
            this.saveJobToS3(job).catch(err => {
                console.error(`Failed to save timeout update for job ${job.jobId}:`, err);
            });
        }
        return job;
    }
    /**
     * å¾ Lambda callback æ›´æ–°ä»»å‹™ç‹€æ…‹
     */
    async updateJobFromCallback(jobId, success, error, metrics) {
        const job = this.jobs.get(jobId);
        if (!job) {
            console.warn(`Job ${jobId} not found for callback update`);
            return;
        }
        try {
            if (success) {
                job.status = vectorIndex_1.VectorIndexStatus.COMPLETED;
                job.stage = vectorIndex_1.VectorIndexStage.COMPLETED;
                job.progress = {
                    current: 100,
                    total: 100,
                    percentage: 100,
                };
                job.completedAt = new Date();
                job.updatedAt = new Date();
                // æ›´æ–°çµ±è¨ˆè³‡æ–™
                if (metrics) {
                    job.processingTime = metrics.processingTime;
                    job.stats = metrics.stats;
                    job.numChunks = metrics.numChunks;
                    job.numVectors = metrics.numVectors;
                    // è¨ˆç®—è²»ç”¨
                    job.costs = this.calculateCosts(metrics);
                }
                console.log(`âœ… Job ${jobId} completed successfully via Lambda callback`);
                if (job.processingTime) {
                    console.log(`   Processing time: ${job.processingTime.toFixed(2)}s`);
                }
                if (job.costs) {
                    console.log(`   Estimated cost: $${job.costs.total.toFixed(6)}`);
                }
            }
            else {
                job.status = vectorIndex_1.VectorIndexStatus.FAILED;
                job.error = error || 'Lambda indexing failed';
                job.updatedAt = new Date();
                console.error(`âŒ Job ${jobId} failed via Lambda callback: ${error}`);
            }
            // ä¿å­˜æ›´æ–°åˆ° S3
            await this.saveJobToS3(job);
        }
        finally {
            // é‡‹æ”¾é–å®š
            this.jobLockManager.releaseFileLock(job.fileId);
            this.jobLockManager.releaseGlobalLock();
            console.log(`ğŸ”“ Locks released for job ${jobId}`);
        }
    }
    /**
     * è¨ˆç®—åŸ·è¡Œè²»ç”¨
     */
    calculateCosts(metrics) {
        const costs = {
            lambda: 0,
            embedding: 0,
            total: 0
        };
        // Lambda è²»ç”¨è¨ˆç®—
        // AWS Lambda å®šåƒ¹ (us-east-1, 2024):
        // - $0.0000166667 per GB-second (128MB = 0.125GB)
        // - $0.20 per 1M requests
        if (metrics.processingTime) {
            const memoryGB = 0.512; // 512MB = 0.5GB
            const gbSeconds = memoryGB * metrics.processingTime;
            costs.lambda = gbSeconds * 0.0000166667 + 0.0000002; // + per request cost
        }
        // OpenAI Embedding API è²»ç”¨
        // text-embedding-3-small: $0.00002 per 1K tokens
        // å‡è¨­å¹³å‡æ¯å€‹ chunk ç´„ 500 tokens
        if (metrics.numVectors) {
            const estimatedTokens = metrics.numVectors * 500;
            costs.embedding = (estimatedTokens / 1000) * 0.00002;
        }
        costs.total = costs.lambda + costs.embedding;
        return costs;
    }
    /**
     * åˆ—å‡ºæ‰€æœ‰ä»»å‹™
     */
    listJobs() {
        const jobs = Array.from(this.jobs.values());
        const now = Date.now();
        const timeout = 15 * 60 * 1000; // 15 åˆ†é˜è¶…æ™‚
        // æª¢æŸ¥ä¸¦æ¨™è¨˜è¶…æ™‚çš„ä»»å‹™ï¼ˆåªæª¢æŸ¥æœªå®Œæˆçš„ä»»å‹™ï¼‰
        for (const job of jobs) {
            if (!job.completedAt && // æ²’æœ‰å®Œæˆæ™‚é–“
                (job.status === vectorIndex_1.VectorIndexStatus.INDEXING ||
                    job.status === vectorIndex_1.VectorIndexStatus.EXTRACTING ||
                    job.status === vectorIndex_1.VectorIndexStatus.PENDING) &&
                now - job.createdAt.getTime() > timeout) {
                console.warn(`Job ${job.jobId} has timed out after ${timeout / 1000}s`);
                job.status = vectorIndex_1.VectorIndexStatus.FAILED;
                job.error = `Timeout: No callback received after ${timeout / 60000} minutes. Lambda may have failed silently.`;
                job.updatedAt = new Date();
                // é‡‹æ”¾é–å®š
                this.jobLockManager.releaseFileLock(job.fileId);
                this.jobLockManager.releaseGlobalLock();
                // ä¿å­˜æ›´æ–°åˆ° S3
                this.saveJobToS3(job).catch(err => {
                    console.error(`Failed to save timeout update for job ${job.jobId}:`, err);
                });
            }
        }
        return jobs;
    }
    /**
     * å–æ¶ˆä»»å‹™
     */
    async cancelJob(jobId) {
        const job = this.jobs.get(jobId);
        if (!job) {
            return false;
        }
        if (job.status === vectorIndex_1.VectorIndexStatus.COMPLETED || job.status === vectorIndex_1.VectorIndexStatus.FAILED) {
            return false;
        }
        job.status = vectorIndex_1.VectorIndexStatus.CANCELLED;
        job.updatedAt = new Date();
        this.jobLockManager.releaseFileLock(job.fileId);
        this.jobLockManager.releaseGlobalLock();
        // ä¿å­˜æ›´æ–°åˆ° S3
        await this.saveJobToS3(job);
        return true;
    }
    /**
     * æœç´¢å‘é‡ç´¢å¼•
     */
    async searchVector(request) {
        const { fileId, query, k = 5, minScore = 0.0 } = request;
        if (!fileId) {
            throw new Error('fileId is required for vector search');
        }
        // 1. å¾ S3 ä¸‹è¼‰ç´¢å¼•å’Œå…ƒæ•¸æ“š
        const indexKey = `vector-indexes/${fileId}.index`;
        const metadataKey = `vector-indexes/${fileId}.metadata.json`;
        let indexBuffer;
        let rawMetadata;
        try {
            // ä¸‹è¼‰ç´¢å¼•æª”æ¡ˆ
            const indexCmd = new client_s3_1.GetObjectCommand({
                Bucket: s3BucketName,
                Key: indexKey,
            });
            const indexResponse = await s3Client.send(indexCmd);
            indexBuffer = await this.streamToBuffer(indexResponse.Body);
            // ä¸‹è¼‰å…ƒæ•¸æ“š
            const metadataCmd = new client_s3_1.GetObjectCommand({
                Bucket: s3BucketName,
                Key: metadataKey,
            });
            const metadataResponse = await s3Client.send(metadataCmd);
            const metadataBuffer = await this.streamToBuffer(metadataResponse.Body);
            rawMetadata = JSON.parse(metadataBuffer.toString('utf-8'));
        }
        catch (error) {
            throw new Error(`Failed to load vector index for file ${fileId}: ${error instanceof Error ? error.message : String(error)}`);
        }
        // 2. å„²å­˜ç´¢å¼•åˆ°è‡¨æ™‚æª”æ¡ˆä¸¦è¼‰å…¥
        const tempIndexPath = path.join(this.tempDir, `search-${fileId}-${Date.now()}.index`);
        fs.writeFileSync(tempIndexPath, indexBuffer);
        const indexManager = new FaissIndexManager_1.FaissIndexManager(this.config.dimensions);
        try {
            await indexManager.load(tempIndexPath);
            // 3. å°‡æŸ¥è©¢æ–‡å­—è½‰ç‚ºå‘é‡
            const queryEmbedding = await this.embeddingService.embedText(query);
            // 4. æœç´¢æœ€è¿‘é„° (FAISS uses Inner Product, higher is better)
            const searchResults = await indexManager.search(queryEmbedding, k);
            // 5. çµ„åˆçµæœ - ä½¿ç”¨å¯¦éš›çš„ metadata æ¬„ä½åç¨±
            const results = [];
            for (let i = 0; i < searchResults.labels.length; i++) {
                const vectorId = searchResults.labels[i];
                const distance = searchResults.distances[i];
                // FAISS Inner Product: higher score = more similar
                const score = distance;
                if (score < minScore) {
                    continue;
                }
                const rawMeta = rawMetadata[vectorId];
                if (rawMeta) {
                    // å°‡åŸå§‹ metadata è½‰æ›ç‚ºæ¨™æº–æ ¼å¼
                    const standardMetadata = {
                        chunkId: `${rawMeta.fileId}-chunk-${rawMeta.chunkIndex}`,
                        fileId: rawMeta.fileId,
                        vectorId: vectorId,
                        content: rawMeta.text || '',
                        startIndex: rawMeta.startWord || 0,
                        endIndex: rawMeta.endWord || 0,
                        chunkOrder: rawMeta.chunkIndex || 0,
                        createdAt: new Date(),
                    };
                    results.push({
                        chunkId: standardMetadata.chunkId,
                        fileId: standardMetadata.fileId,
                        content: standardMetadata.content,
                        score,
                        metadata: standardMetadata,
                    });
                }
            }
            return results;
        }
        finally {
            // æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            if (fs.existsSync(tempIndexPath)) {
                fs.unlinkSync(tempIndexPath);
            }
        }
    }
    /**
     * è¼”åŠ©å‡½æ•¸ï¼šå°‡ Stream è½‰ç‚º Buffer
     */
    async streamToBuffer(stream) {
        const chunks = [];
        for await (const chunk of stream) {
            chunks.push(chunk);
        }
        return Buffer.concat(chunks);
    }
    /**
     * Search across all indexed manuals simultaneously
     */
    async searchAllManuals(query, k = 5, minScore = 0.5) {
        try {
            const listCmd = new client_s3_1.ListObjectsV2Command({
                Bucket: s3BucketName,
                Prefix: 'vector-indexes/',
            });
            const response = await s3Client.send(listCmd);
            const indexFiles = (response.Contents || [])
                .filter((obj) => obj.Key?.endsWith('.index'))
                .map((obj) => {
                const match = obj.Key?.match(/vector-indexes\/(.+)\.index$/);
                return match ? match[1] : null;
            })
                .filter((id) => id !== null);
            if (indexFiles.length === 0) {
                return [];
            }
            // Search each file and collect results
            const allResults = [];
            for (const fileId of indexFiles) {
                try {
                    const results = await this.searchVector({
                        fileId,
                        query,
                        k: Math.ceil(k / indexFiles.length) + 2,
                        minScore,
                    });
                    allResults.push(...results);
                }
                catch (error) {
                    console.error(`Failed to search file ${fileId}:`, error);
                }
            }
            // Sort by score and return top k
            allResults.sort((a, b) => b.score - a.score);
            return allResults.slice(0, k);
        }
        catch (error) {
            throw new Error(`Failed to search all manuals: ${error instanceof Error ? error.message : String(error)}`);
        }
    }
    /**
     * å¾ S3 è¼‰å…¥æ‰€æœ‰ jobs
     */
    async loadJobsFromS3() {
        if (this.jobsLoaded)
            return;
        try {
            console.log('Loading jobs from S3...');
            const { ListObjectsV2Command } = await Promise.resolve().then(() => __importStar(require('@aws-sdk/client-s3')));
            const listCommand = new ListObjectsV2Command({
                Bucket: s3BucketName,
                Prefix: 'jobs/',
            });
            const listResponse = await s3Client.send(listCommand);
            if (!listResponse.Contents || listResponse.Contents.length === 0) {
                console.log('No jobs found in S3');
                this.jobsLoaded = true;
                return;
            }
            const cutoffDate = new Date();
            cutoffDate.setDate(cutoffDate.getDate() - this.JOB_RETENTION_DAYS);
            let loadedCount = 0;
            let skippedCount = 0;
            for (const item of listResponse.Contents) {
                if (!item.Key || !item.Key.endsWith('.json'))
                    continue;
                // æª¢æŸ¥æ˜¯å¦éæœŸ
                if (item.LastModified && item.LastModified < cutoffDate) {
                    skippedCount++;
                    continue;
                }
                try {
                    const getCommand = new client_s3_1.GetObjectCommand({
                        Bucket: s3BucketName,
                        Key: item.Key,
                    });
                    const response = await s3Client.send(getCommand);
                    const jobData = await this.streamToBuffer(response.Body);
                    const job = JSON.parse(jobData.toString('utf-8'));
                    // è½‰æ›æ—¥æœŸå­—ä¸²ç‚º Date ç‰©ä»¶
                    job.createdAt = new Date(job.createdAt);
                    job.updatedAt = new Date(job.updatedAt);
                    if (job.completedAt) {
                        job.completedAt = new Date(job.completedAt);
                    }
                    this.jobs.set(job.jobId, job);
                    loadedCount++;
                }
                catch (error) {
                    console.error(`Failed to load job from ${item.Key}:`, error);
                }
            }
            console.log(`âœ“ Loaded ${loadedCount} jobs from S3 (skipped ${skippedCount} old jobs)`);
            this.jobsLoaded = true;
        }
        catch (error) {
            console.error('Error loading jobs from S3:', error);
            this.jobsLoaded = true;
        }
    }
    /**
     * ä¿å­˜å–®å€‹ job åˆ° S3
     */
    async saveJobToS3(job) {
        try {
            const jobKey = `jobs/${job.jobId}.json`;
            const jobData = JSON.stringify(job, null, 2);
            await s3Client.send(new client_s3_1.PutObjectCommand({
                Bucket: s3BucketName,
                Key: jobKey,
                Body: jobData,
                ContentType: 'application/json',
            }));
            // console.log(`âœ“ Saved job ${job.jobId} to S3`);
        }
        catch (error) {
            console.error(`Failed to save job ${job.jobId} to S3:`, error);
        }
    }
    /**
     * å¾ S3 åˆªé™¤éæœŸçš„ jobs
     */
    async cleanupOldJobsFromS3() {
        try {
            const { ListObjectsV2Command, DeleteObjectCommand } = await Promise.resolve().then(() => __importStar(require('@aws-sdk/client-s3')));
            const listCommand = new ListObjectsV2Command({
                Bucket: s3BucketName,
                Prefix: 'jobs/',
            });
            const listResponse = await s3Client.send(listCommand);
            if (!listResponse.Contents)
                return;
            const cutoffDate = new Date();
            cutoffDate.setDate(cutoffDate.getDate() - this.JOB_RETENTION_DAYS);
            let deletedCount = 0;
            for (const item of listResponse.Contents) {
                if (!item.Key || !item.LastModified)
                    continue;
                if (item.LastModified < cutoffDate) {
                    try {
                        await s3Client.send(new DeleteObjectCommand({
                            Bucket: s3BucketName,
                            Key: item.Key,
                        }));
                        deletedCount++;
                    }
                    catch (error) {
                        console.error(`Failed to delete old job ${item.Key}:`, error);
                    }
                }
            }
            if (deletedCount > 0) {
                console.log(`âœ“ Cleaned up ${deletedCount} old jobs from S3`);
            }
        }
        catch (error) {
            console.error('Error cleaning up old jobs from S3:', error);
        }
    }
}
exports.VectorIndexService = VectorIndexService;
// å–®ä¾‹
exports.vectorIndexService = new VectorIndexService();
